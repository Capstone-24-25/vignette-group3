```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Primary Vignette - Classification Strategies

**Objectives**

-   Perform exploratory data analysis

-   Reduce dimensionality using principal component analysis

-   Employ logistic regression using `glm()` and `multinom()`

-   Building a random forest model using `randomForest()`

We'll illustrate these strategies using the `California Household Travel Survey (CHTS)` dataset.

```{r, message=F, warning=F}
# Loading necessary packages
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(sparsesvd)
library(nnet)
library(sf)
library(mapview)
mapviewOptions(fgb = FALSE)
library(leafsync)
library(maps)
library(nnet)
library(randomForest)

# Read in datasets
PersonData <- read_rds('./Data/raw/PersonData_111A.Rds')
HHData <- read_rds('./Data/raw/HHData_111A.Rds')
hh_bgDensity <- read_rds('./Data/raw/hh_bgDensity.Rds')
county_shp <- st_read("./Data/raw/counties/counties.shp")

# Merge datasets
personHHData <- left_join(PersonData, HHData) %>%
  left_join(hh_bgDensity)

# Preprocess data
numeric_columns <- sapply(personHHData, is.numeric)

numeric_data <- personHHData[, numeric_columns]

numeric_data <- numeric_data %>% select(-CTFIP, -hhid, -bg_density)

scaled_data <- scale(numeric_data)

hhid <- personHHData$hhid
bg_group <- personHHData$bg_group
scaled_data <- cbind(hhid, bg_group, scaled_data)

scaled_data_clean <- na.omit(scaled_data) %>% 
  as.data.frame() %>% 
  mutate(bg_group = as.factor(bg_group))

```

## Exploratory Data Analysis

Before we partition our data and fit classification models, we want to get to know our data through some exploratory visualizations. Since our data is geographically structured, we found it helpful to visualize our data on a map.

### Static Map

```{r, message=F, warning=F}
county_bg_aggreg <- personHHData %>% 
  group_by(County, CTFIP, bg_group) %>%  # group by county, CTFIP, and also bg_group
  mutate(count = n()) %>% 
  summarise_at(vars(-hhid, -pnum), mean)

county_bg_shp <- county_shp %>% 
  merge(data.frame(bg_group = c("Urban", "Suburban", "Exurban", "Rural"))) %>% 
  left_join(county_bg_aggreg)

# get the CA county data
county <- ggplot2::map_data("county", region = "california")

county_bg <- merge(county, data.frame(bg_group = c("Urban", "Suburban", "Exurban", "Rural")))

county_bg_all <- county_bg_aggreg %>% 
  mutate(subregion = tolower(County)) %>% 
  full_join(county_bg, by = c("subregion", "bg_group"))

ggplot(county_bg_all) +
  geom_polygon(aes(x = long, y = lat, group = subregion, fill = Sum_PMT), colour = "white") +
  scale_fill_distiller(palette = "YlGnBu", direction = 1) +
  facet_wrap(vars(bg_group), nrow = 2) +  # multi-panel plots using facet_wrap(), plot in 2 rows
  ggtitle("Total PMT in California at County-level") + 
  theme_void() +
  theme(legend.position="bottom")
```

These maps show the total distance traveled by country. The grey counties represent missing data.

### Sum Trips by Residential Area

```{r, message=F, warning=F}
urban_TripMap <-  mapview(filter(county_bg_shp, bg_group == "Urban"),
                          zcol = "Sum_Trips", legend = TRUE, popup = NULL,
                          layer.name = "Urban Trips")

suburb_TripMap <- mapview(filter(county_bg_shp, bg_group == "Suburban"),
                          zcol = "Sum_Trips", legend = TRUE, popup = NULL,
                          layer.name = "Suburban Trips")

exurb_TripMap <- mapview(filter(county_bg_shp, bg_group == "Exurban"),
                         zcol = "Sum_Trips", legend = TRUE, popup = NULL,
                         layer.name = "Exurban Trips")

rural_TripMap <- mapview(filter(county_bg_shp, bg_group == "Rural"),
                         zcol = "Sum_Trips", legend = TRUE, popup = NULL,
                         layer.name = "Rural Trips")

latticeview(urban_TripMap, suburb_TripMap, exurb_TripMap, rural_TripMap, sync = "all")
```

This visual represents the number of trips per county by household density categories (urban, suburban, exurban, and rural).

## Data Partitioning

Before fitting models, it is imperative to split our data into a training set and a testing set. We will use the training set to train our models. Once our models are trained, we will fit the best model to the testing set and see how it truly performs. We are employing the 80/20 split, where 80% of the data goes to the training data and 30% of the data goes to the testing data. This ensures that there is data to both train our models and properly test model performance. `set.seed()` is used to ensure reproducibility of our findings.

```{r}
# Set seed
set.seed(14531)

# Partition data
partitions <- scaled_data_clean %>% 
  initial_split(prop = 0.8)

# Separate id and response variable in testing and training data
test_dtm <- testing(partitions) %>% 
  select(-hhid, -bg_group)
test_labels <- testing(partitions) %>% 
  select(hhid, bg_group)

train_dtm <- training(partitions) %>% 
  select(-hhid, -bg_group)
train_labels <- training(partitions) %>%
  select(hhid, bg_group)
```

## Principal Component Analysis

To reduce the dimensionality of the dataset, we employ PCA.

#### Step 1: Visualizing variance explained by principal components

First, determine how many principal components to retain based on their respective variance.

```{r}
# Explained variance plot
singular_values <- train_svd$d
variance_explained <- (singular_values^2) / sum(singular_values^2)

plot(variance_explained, type = "b", xlab = "Principal Component",
     ylab = "Proportion of Variance Explained", main = "Scree Plot")
abline(h = 0.1, col = "red", lty = 2)

# Cumulative variance plot
cumulative_variance <- cumsum(variance_explained)

plot(cumulative_variance, type = "b", xlab = "Principal Component",
     ylab = "Cumulative Variance Explained", main = "Cumulative Variance")

# Set the threshold for the cumulative variance (80%)
threshold <- 0.8
reduced_pcs <- which(cumulative_variance >= threshold)[1]

# Print the number of PCs to keep
cat("Number of PCs to retain:", reduced_pcs)

# Plot PC1 vs PC2
plot(training_projected$PC1, training_projected$PC2, xlab = "PC1", ylab = "PC2",
     main = "PCA - PC1 vs PC2", pch = 19, col = "blue")
```

#### Step 2: Perform PCA on training data

```{r}
# Set seed
set.seed(14531)

# Convert training data to sparse matrix to use sparsesvd function to perform PCA
train_dtm_sparse <- as.matrix(train_dtm) %>% 
  as("sparseMatrix")

# Perform PCA on sparse training data matrix and turn into dataframe
train_svd <- sparsesvd(train_dtm_sparse, rank = 18)
training_projected <- as.data.frame(train_svd$u %*% diag(train_svd$d))

# Assign column names
colnames(training_projected) <- paste0("PC", 1:ncol(training_projected))
```

#### Step 3: Project testing data onto training PCA

```{r}
# Set seed
set.seed(14531)

# Define function
reproject_fn <- function(.dtm, train_projected) {
  .dtm_sparse <- as(.dtm, "sparseMatrix")
  test_projected <- as.matrix(.dtm_sparse %*% train_projected$v %*% diag(1 / train_projected$d))
  colnames(test_projected) <- paste0("PC", 1:ncol(test_projected))
  return(test_projected)
}

# Project
test_projected <- reproject_fn(test_dtm, train_svd)
```

Now, the dataset has been transformed.

## Logistic Regression

Now that we have reduced the dimensionality of the dataset, we can feed the transformed data into the logistic regression model.

### Step 1: Get the reduced PCA data that you will feed into logistic regression model

```{r}
training_projected_reduced <- training_projected[, 1:reduced_pcs]
test_projected_reduced <- test_projected[, 1:reduced_pcs]

reduced_training <- cbind(training_projected_reduced, bg_group = train_labels$bg_group)

reduced_testing <- cbind(as.data.frame(test_projected_reduced), bg_group = test_labels$bg_group)
```

### Step 2: Fit logistic regression model with the PCA reduced training data

```{r}
log_regmodel <- multinom(bg_group ~ ., data = reduced_training)
```

Let's see how well our model was able to classify the different household densities

```{r}
logreg_test_predictions <- predict(log_regmodel, newdata = reduced_testing)
```

### Step 3: Accuracy measures

Finally, look at the accuracy of the logistic regression model by summing across the diagonal of the confusion matrix.

```{r}
# Create a confusion matrix
conf_matrix <- table(Predicted = logreg_test_predictions, Actual = reduced_testing$bg_group)

# Calculate overall accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
```

As you can see, the low accuracy indicates that PCA might not be the best approach for the logistic regression model.

## Random Forest

### Step 1: Set up the data for RandomForest modelling

For the `randomForest()` function, create dataframes that has all predictive variables, using data from before the PCA, and include response variable `bg_group`.

```{r}
#training
training <- training(partitions) %>% select(-hhid)

#testing
testing <- testing(partitions) %>% select(-hhid)
```

### Step 2: Fit Random Forest model with training data

Fit Random Forest model on training data using 300 trees, 20 predictor variables randomly selected at each tree split, and making sure variable importance is being calculated.

```{r}
set.seed(14531)
rf_model <- randomForest(bg_group ~ ., data = training, ntree = 300, mtry = 20, importance = TRUE)

```

### Step 3: Accuracy Measures

Lastly, look at the confusion matrix for the Random Forest model and calculate the accuracy to see how well the model performed.

```{r}
#Evaluate the Model
predictions <- predict(rf_model, newdata = testing)

#confusion matrix
confusion_matrix <- table(Predicted = predictions, Actual = reduced_testing$bg_group)
print(confusion_matrix)

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 4)))
```

With an accuracy of 0.4058, the model performed better than the logistic regression with PCA.

### Step 4: Variable Importance

We can also take a look at which variables were most important in explaining the variation in the `bg_group` variation. The household home type was the most important, followed by the number of public transit riders in the household and the number of walking trips taken the week of the survey.

```{r}
# Plot variable importance with top 10 important variables
rf_models %>% 
  vip() +
  theme_minimal()
```
